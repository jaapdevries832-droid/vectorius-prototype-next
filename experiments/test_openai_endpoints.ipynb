{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-vec-aoai",
   "metadata": {},
   "source": [
    "# üî¨ Vectorius ‚Äî Azure OpenAI Proof (Lesson 15)\n",
    "\n",
    "This notebook connects to your **Azure OpenAI** deployment and loads **Markdown prompts** from `/prompts` so you can edit pedagogy without touching code.\n",
    "\n",
    "### What this does\n",
    "1. Load credentials from `web/.env.local`\n",
    "2. Read `prompts/grade8_system.md` + a mode file (`tutor | checker | explainer`)\n",
    "3. Initialize Azure OpenAI client\n",
    "4. Send a test chat completion using the same prompt stack as the web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env-load",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from web/.env.local (run from /experiments or similar)\n",
    "ok = load_dotenv(dotenv_path=\"../web/.env.local\")\n",
    "ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-echo",
   "metadata": {},
   "source": [
    "## 1) Verify environment variables\n",
    "We expect **all three** below to be set in `web/.env.local`:\n",
    "\n",
    "```ini\n",
    "AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/\n",
    "AZURE_OPENAI_API_KEY=***\n",
    "AZURE_OPENAI_DEPLOYMENT=<your-deployment-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env-vars",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: https://jaapd-meryoqet-eastus2.cognitiveservices.azure.com/\n",
      "Deployment: gpt-4.1-mini-vectorius\n",
      "Key loaded: ‚úîÔ∏è\n"
     ]
    }
   ],
   "source": [
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "\n",
    "print(\"Endpoint:\", endpoint)\n",
    "print(\"Deployment:\", deployment)\n",
    "print(\"Key loaded:\", \"‚úîÔ∏è\" if api_key else \"‚ùå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-loader-md",
   "metadata": {},
   "source": [
    "## 2) Load Markdown prompts (shared with the web app)\n",
    "Prompts live in the repo root under `/prompts`. We read them via the small helper in `/experiments/prompt_loader.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prompt-loader-import",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt length: 2215\n",
      "Tutor/Checker/Explainer lengths: 735 657 690\n"
     ]
    }
   ],
   "source": [
    "# Make sure we can import experiments/prompt_loader.py from anywhere\n",
    "# import sys, pathlib\n",
    "\n",
    "# here = pathlib.Path.cwd()\n",
    "# for p in [here, *here.parents]:\n",
    "#     exp = p / \"experiments\"\n",
    "#     if (exp / \"prompt_loader.py\").exists():\n",
    "#         sys.path.insert(0, str(exp))   # add /experiments to import path\n",
    "#         break\n",
    "\n",
    "from prompt_loader import read_prompt  # <-- now this works\n",
    "\n",
    "system_text = read_prompt(\"grade8_system.md\")\n",
    "tutor_text  = read_prompt(\"tutor_mode.md\")\n",
    "checker_text = read_prompt(\"checker_mode.md\")\n",
    "explainer_text = read_prompt(\"explainer_mode.md\")\n",
    "\n",
    "print(\"System prompt length:\", len(system_text))\n",
    "print(\"Tutor/Checker/Explainer lengths:\", len(tutor_text), len(checker_text), len(explainer_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7cd8daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: c:\\Users\\Innovation4\\Documents\\Vectorius\\vectorius-prototype-next\\experiments\n",
      "read_prompt OK: True\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "print(\"CWD:\", pathlib.Path.cwd())\n",
    "print(\"read_prompt OK:\", len(read_prompt(\"grade8_system.md\")) > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "client-init-md",
   "metadata": {},
   "source": [
    "## 3) Initialize Azure OpenAI client\n",
    "Uses the official `openai` Python SDK in Azure mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "client-init",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client ready ‚úîÔ∏è\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "api_version = \"2024-12-01-preview\"  # adjust to your Azure portal version\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=endpoint\n",
    ")\n",
    "print(\"Client ready ‚úîÔ∏è\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-md",
   "metadata": {},
   "source": [
    "## 4) Helpers to build messages with mode\n",
    "Mode can be one of: `tutor`, `checker`, or `explainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helpers-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_with_mode(user_text: str, mode: str = \"tutor\"):\n",
    "    mode = (mode or \"tutor\").lower().strip()\n",
    "    if mode == \"checker\":\n",
    "        mode_text = checker_text\n",
    "    elif mode == \"explainer\":\n",
    "        mode_text = explainer_text\n",
    "    else:\n",
    "        mode_text = tutor_text\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_text},\n",
    "        {\"role\": \"system\", \"content\": mode_text},\n",
    "        {\"role\": \"user\", \"content\": user_text},\n",
    "    ]\n",
    "\n",
    "def chat_once(user_text: str, mode: str = \"tutor\", temperature: float = 0.4):\n",
    "    msgs = messages_with_mode(user_text, mode)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=msgs,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-tutor-md",
   "metadata": {},
   "source": [
    "## 5) Tests\n",
    "- Tutor mode ‚Üí asks for attempt, gives hint\n",
    "- Checker mode ‚Üí rubric + fixes + next step\n",
    "- Explainer mode ‚Üí short concept + different example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "test-modes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutor mode:\n",
      "Hi! What do you already know about King Tut?  \n",
      "If you‚Äôre not sure, that‚Äôs okay!  \n",
      "\n",
      "- **Hint:** Start by finding out when King Tut lived and why he is famous.  \n",
      "- **Why it helps:** Knowing the time period and his significance gives a clear picture of who he was.  \n",
      "- **Your turn:** Can you try to write one or two sentences about when King Tut lived or what he is known for?\n",
      "\n",
      "Checker mode:\n",
      "- **Rubric:**  \n",
      "  1. Accuracy of historical facts  \n",
      "  2. Clarity and completeness of information  \n",
      "\n",
      "- **Top fixes:**  \n",
      "  1. \"Farao\" should be spelled \"pharaoh.\"  \n",
      "  2. The date \"around 1000 BC\" might need to be more precise or supported with context (which pharaoh?).\n",
      "\n",
      "- **Next step:**  \n",
      "  Check your facts about which pharaoh you mean and add one or two key details about their reign or significance.\n",
      "\n",
      "Explainer mode:\n",
      "Could you tell me which King Uts you mean? There are different kings with similar names in history. If you mean a specific one, like from a certain country or time period, I can help explain more about his life!\n"
     ]
    }
   ],
   "source": [
    "print(\"Tutor mode:\")\n",
    "print(chat_once(\"Who was king tut?\", mode=\"tutor\"))\n",
    "\n",
    "print(\"\\nChecker mode:\")\n",
    "student_attempt = \"I know he was a farao in Egypt and he lived around 1000 BC.\"\n",
    "print(chat_once(f\"PLease check my asnwer: {student_attempt}\", mode=\"checker\"))\n",
    "\n",
    "print(\"\\nExplainer mode:\")\n",
    "print(chat_once(\"Tell me more about King Uts life.\", mode=\"explainer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6123c5",
   "metadata": {},
   "source": [
    "## Testing the CURL Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b19c649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Response: {'reply': 'Hi! What have you tried so far with the equation 2x + 5 = 17?'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Local Next.js server URL\n",
    "url = \"http://localhost:3000/api/chat\"\n",
    "\n",
    "payload = {\n",
    "    \"question\": \"help me solve 2x+5=17\",\n",
    "    \"mode\": \"tutor\"\n",
    "}\n",
    "\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "resp = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "print(\"Status:\", resp.status_code)\n",
    "print(\"Response:\", resp.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc3e98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e8c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
